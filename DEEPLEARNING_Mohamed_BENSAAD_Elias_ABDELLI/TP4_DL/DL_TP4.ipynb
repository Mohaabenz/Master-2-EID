{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_TP4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9dfq3-OAHkr",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Autors Mohamed BEN SAAD & Elias ABDELLI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qZo1EolPfpA",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Importation Library \n",
        "import  numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets\n",
        "from sklearn import decomposition\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M11nLruFXLwO",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Model_exec\n",
        "def Model_exec(batch_size, nbr_neural, epochs, activation_function='relu', output_activation=False):\n",
        "  inputs = keras.Input(shape=(784,), name='digits')\n",
        "  x = layers.Dense(nbr_neural, activation=activation_function, name='dense_1')(inputs)\n",
        "  if output_activation : \n",
        "    outputs = layers.Dense(10,activation=output_activation, name='predictions')(x)\n",
        "  else:\n",
        "    outputs = layers.Dense(10, name='predictions')(x)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "  x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "  x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
        "  y_train = y_train.astype('float32')\n",
        "  y_test = y_test.astype('float32')\n",
        "  x_val = x_train[-10000:]\n",
        "  y_val = y_train[-10000:]\n",
        "  x_train = x_train[:-10000]\n",
        "  y_train = y_train[:-10000]\n",
        "  model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1),  # Optimizer\n",
        "                # Loss function to minimize\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                # List of metrics to monitor\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "  print('# Fit model on training data')\n",
        "  history = model.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_data=(x_val, y_val))\n",
        "  print('history dict:', history.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErLtpAhaXcwu",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "e58e3354-5e4a-4302-fc61-ddc5bbe936b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "#@title Sigmoid 100 neurones\n",
        "Model_exec(nbr_neural=100,batch_size=100,epochs=1, activation_function='sigmoid')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "# Fit model on training data\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 13.2863 - sparse_categorical_accuracy: 0.5317 - val_loss: 6.0941 - val_sparse_categorical_accuracy: 0.7026\n",
            "\n",
            "history dict: {'loss': [13.286271095275879], 'sparse_categorical_accuracy': [0.5317000150680542], 'val_loss': [6.094098091125488], 'val_sparse_categorical_accuracy': [0.7026000022888184]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0w73vVBe_rM",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "bf29aaa8-0766-44f5-90c3-c8fa81a33067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#@title Outputsoftmax 5 Iterations\n",
        "Model_exec(nbr_neural=20 ,batch_size=1000,epochs=5, output_Activation_function='softmax' , activation_function='sigmoid')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Fit model on training data\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 2.1987 - sparse_categorical_accuracy: 0.2568 - val_loss: 2.1683 - val_sparse_categorical_accuracy: 0.2863\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1687 - sparse_categorical_accuracy: 0.2899 - val_loss: 2.1663 - val_sparse_categorical_accuracy: 0.2941\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1657 - sparse_categorical_accuracy: 0.2940 - val_loss: 2.1684 - val_sparse_categorical_accuracy: 0.2916\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1638 - sparse_categorical_accuracy: 0.2968 - val_loss: 2.1704 - val_sparse_categorical_accuracy: 0.2906\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1619 - sparse_categorical_accuracy: 0.2983 - val_loss: 2.1658 - val_sparse_categorical_accuracy: 0.2950\n",
            "\n",
            "history dict: {'loss': [2.1986594200134277, 2.1686716079711914, 2.165654182434082, 2.163766860961914, 2.1618869304656982], 'sparse_categorical_accuracy': [0.2568199932575226, 0.28992000222206116, 0.2940399944782257, 0.2967599928379059, 0.2983199954032898], 'val_loss': [2.1682753562927246, 2.1663079261779785, 2.1684319972991943, 2.170440196990967, 2.1657702922821045], 'val_sparse_categorical_accuracy': [0.28630000352859497, 0.29409998655319214, 0.29159998893737793, 0.2906000018119812, 0.29499998688697815]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4_x4LkSi5S6",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "f7e049db-bd6c-496d-d727-3aec798a34c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "#@title Outputsoftmax 20 Iterations\n",
        "Model_exec(nbr_neural=20 ,batch_size=1000,epochs=20, output_Activation_function='softmax' , activation_function='sigmoid')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Fit model on training data\n",
            "Epoch 1/20\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 2.2316 - sparse_categorical_accuracy: 0.2258 - val_loss: 2.1837 - val_sparse_categorical_accuracy: 0.2709\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1892 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.1879 - val_sparse_categorical_accuracy: 0.2708\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1760 - sparse_categorical_accuracy: 0.2835 - val_loss: 2.1672 - val_sparse_categorical_accuracy: 0.2923\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1712 - sparse_categorical_accuracy: 0.2887 - val_loss: 2.1709 - val_sparse_categorical_accuracy: 0.2900\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1764 - sparse_categorical_accuracy: 0.2834 - val_loss: 2.1746 - val_sparse_categorical_accuracy: 0.2863\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1739 - sparse_categorical_accuracy: 0.2861 - val_loss: 2.1727 - val_sparse_categorical_accuracy: 0.2860\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1694 - sparse_categorical_accuracy: 0.2907 - val_loss: 2.1669 - val_sparse_categorical_accuracy: 0.2935\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1687 - sparse_categorical_accuracy: 0.2914 - val_loss: 2.1666 - val_sparse_categorical_accuracy: 0.2944\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1665 - sparse_categorical_accuracy: 0.2939 - val_loss: 2.1718 - val_sparse_categorical_accuracy: 0.2883\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1690 - sparse_categorical_accuracy: 0.2913 - val_loss: 2.1952 - val_sparse_categorical_accuracy: 0.2655\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1717 - sparse_categorical_accuracy: 0.2889 - val_loss: 2.1773 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1639 - sparse_categorical_accuracy: 0.2967 - val_loss: 2.1710 - val_sparse_categorical_accuracy: 0.2902\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1684 - sparse_categorical_accuracy: 0.2920 - val_loss: 2.1711 - val_sparse_categorical_accuracy: 0.2895\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1668 - sparse_categorical_accuracy: 0.2939 - val_loss: 2.1763 - val_sparse_categorical_accuracy: 0.2831\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1665 - sparse_categorical_accuracy: 0.2942 - val_loss: 2.1702 - val_sparse_categorical_accuracy: 0.2911\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1654 - sparse_categorical_accuracy: 0.2955 - val_loss: 2.1709 - val_sparse_categorical_accuracy: 0.2899\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1673 - sparse_categorical_accuracy: 0.2933 - val_loss: 2.1675 - val_sparse_categorical_accuracy: 0.2933\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1651 - sparse_categorical_accuracy: 0.2954 - val_loss: 2.1748 - val_sparse_categorical_accuracy: 0.2862\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1647 - sparse_categorical_accuracy: 0.2960 - val_loss: 2.1654 - val_sparse_categorical_accuracy: 0.2958\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1652 - sparse_categorical_accuracy: 0.2956 - val_loss: 2.1728 - val_sparse_categorical_accuracy: 0.2882\n",
            "\n",
            "history dict: {'loss': [2.2316150665283203, 2.1891591548919678, 2.175989866256714, 2.1711812019348145, 2.1764109134674072, 2.173919916152954, 2.1694257259368896, 2.1687376499176025, 2.1665306091308594, 2.168964147567749, 2.171720027923584, 2.1638877391815186, 2.168368101119995, 2.166764259338379, 2.166459560394287, 2.1653568744659424, 2.1673433780670166, 2.16505765914917, 2.1646578311920166, 2.1651623249053955], 'sparse_categorical_accuracy': [0.22575999796390533, 0.27004000544548035, 0.2834799885749817, 0.2887200117111206, 0.2833999991416931, 0.2861199975013733, 0.2906799912452698, 0.29137998819351196, 0.2939000129699707, 0.29128000140190125, 0.28887999057769775, 0.2967199981212616, 0.2919600009918213, 0.29392001032829285, 0.29420000314712524, 0.2955000102519989, 0.29326000809669495, 0.29541999101638794, 0.295960009098053, 0.29561999440193176], 'val_loss': [2.18371319770813, 2.1878821849823, 2.167233943939209, 2.17087984085083, 2.1745829582214355, 2.1727187633514404, 2.1669111251831055, 2.166593074798584, 2.1717658042907715, 2.1951515674591064, 2.1772561073303223, 2.1710104942321777, 2.171072244644165, 2.176267385482788, 2.170164108276367, 2.170926094055176, 2.1675424575805664, 2.1747939586639404, 2.165370464324951, 2.172830104827881], 'val_sparse_categorical_accuracy': [0.27090001106262207, 0.27079999446868896, 0.2922999858856201, 0.28999999165534973, 0.28630000352859497, 0.28600001335144043, 0.29350000619888306, 0.29440000653266907, 0.2883000075817108, 0.265500009059906, 0.28360000252723694, 0.29019999504089355, 0.28949999809265137, 0.2831000089645386, 0.29109999537467957, 0.289900004863739, 0.29330000281333923, 0.28619998693466187, 0.29580000042915344, 0.2881999909877777]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBNvyfI4i9VX",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "057b3ae1-05c2-474f-97cf-53382ec1efe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Outputsoftmax 50 Iterations\n",
        "Model_exec(nbr_neural=20 ,batch_size=1000,epochs=50, output_Activation_function='softmax' , activation_function='sigmoid')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Fit model on training data\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 2.2851 - sparse_categorical_accuracy: 0.1726 - val_loss: 2.2768 - val_sparse_categorical_accuracy: 0.1838\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.2694 - sparse_categorical_accuracy: 0.1902 - val_loss: 2.2721 - val_sparse_categorical_accuracy: 0.1886\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.2687 - sparse_categorical_accuracy: 0.1915 - val_loss: 2.2692 - val_sparse_categorical_accuracy: 0.1874\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.2233 - sparse_categorical_accuracy: 0.2366 - val_loss: 2.2311 - val_sparse_categorical_accuracy: 0.2322\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1880 - sparse_categorical_accuracy: 0.2719 - val_loss: 2.1773 - val_sparse_categorical_accuracy: 0.2838\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1814 - sparse_categorical_accuracy: 0.2787 - val_loss: 2.1765 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1847 - sparse_categorical_accuracy: 0.2754 - val_loss: 2.1946 - val_sparse_categorical_accuracy: 0.2652\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1843 - sparse_categorical_accuracy: 0.2764 - val_loss: 2.1766 - val_sparse_categorical_accuracy: 0.2840\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1818 - sparse_categorical_accuracy: 0.2789 - val_loss: 2.1766 - val_sparse_categorical_accuracy: 0.2838\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1805 - sparse_categorical_accuracy: 0.2800 - val_loss: 2.2216 - val_sparse_categorical_accuracy: 0.2394\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 2.1863 - sparse_categorical_accuracy: 0.2743 - val_loss: 2.1749 - val_sparse_categorical_accuracy: 0.2860\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1738 - sparse_categorical_accuracy: 0.2869 - val_loss: 2.1745 - val_sparse_categorical_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1768 - sparse_categorical_accuracy: 0.2840 - val_loss: 2.1761 - val_sparse_categorical_accuracy: 0.2849\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1874 - sparse_categorical_accuracy: 0.2734 - val_loss: 2.1834 - val_sparse_categorical_accuracy: 0.2776\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1766 - sparse_categorical_accuracy: 0.2839 - val_loss: 2.1761 - val_sparse_categorical_accuracy: 0.2848\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1758 - sparse_categorical_accuracy: 0.2850 - val_loss: 2.1793 - val_sparse_categorical_accuracy: 0.2807\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1814 - sparse_categorical_accuracy: 0.2792 - val_loss: 2.1814 - val_sparse_categorical_accuracy: 0.2796\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1791 - sparse_categorical_accuracy: 0.2815 - val_loss: 2.1778 - val_sparse_categorical_accuracy: 0.2834\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1763 - sparse_categorical_accuracy: 0.2845 - val_loss: 2.1760 - val_sparse_categorical_accuracy: 0.2842\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1801 - sparse_categorical_accuracy: 0.2807 - val_loss: 2.1854 - val_sparse_categorical_accuracy: 0.2756\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1897 - sparse_categorical_accuracy: 0.2711 - val_loss: 2.2173 - val_sparse_categorical_accuracy: 0.2451\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1826 - sparse_categorical_accuracy: 0.2783 - val_loss: 2.1833 - val_sparse_categorical_accuracy: 0.2780\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1797 - sparse_categorical_accuracy: 0.2809 - val_loss: 2.1756 - val_sparse_categorical_accuracy: 0.2854\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1800 - sparse_categorical_accuracy: 0.2808 - val_loss: 2.1759 - val_sparse_categorical_accuracy: 0.2852\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1784 - sparse_categorical_accuracy: 0.2826 - val_loss: 2.1851 - val_sparse_categorical_accuracy: 0.2760\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1825 - sparse_categorical_accuracy: 0.2784 - val_loss: 2.1746 - val_sparse_categorical_accuracy: 0.2865\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1784 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.1802 - val_sparse_categorical_accuracy: 0.2809\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1819 - sparse_categorical_accuracy: 0.2791 - val_loss: 2.1779 - val_sparse_categorical_accuracy: 0.2832\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1832 - sparse_categorical_accuracy: 0.2779 - val_loss: 2.1903 - val_sparse_categorical_accuracy: 0.2708\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1854 - sparse_categorical_accuracy: 0.2757 - val_loss: 2.1869 - val_sparse_categorical_accuracy: 0.2742\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1826 - sparse_categorical_accuracy: 0.2785 - val_loss: 2.1818 - val_sparse_categorical_accuracy: 0.2793\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 2.1875 - sparse_categorical_accuracy: 0.2735 - val_loss: 2.1798 - val_sparse_categorical_accuracy: 0.2813\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1818 - sparse_categorical_accuracy: 0.2791 - val_loss: 2.1748 - val_sparse_categorical_accuracy: 0.2861\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1730 - sparse_categorical_accuracy: 0.2880 - val_loss: 2.1763 - val_sparse_categorical_accuracy: 0.2848\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1739 - sparse_categorical_accuracy: 0.2872 - val_loss: 2.1754 - val_sparse_categorical_accuracy: 0.2856\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1757 - sparse_categorical_accuracy: 0.2853 - val_loss: 2.1762 - val_sparse_categorical_accuracy: 0.2849\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1832 - sparse_categorical_accuracy: 0.2777 - val_loss: 2.1793 - val_sparse_categorical_accuracy: 0.2811\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1792 - sparse_categorical_accuracy: 0.2817 - val_loss: 2.1765 - val_sparse_categorical_accuracy: 0.2846\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 2.1737 - sparse_categorical_accuracy: 0.2873 - val_loss: 2.1743 - val_sparse_categorical_accuracy: 0.2868\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 2.1749 - sparse_categorical_accuracy: 0.2861 - val_loss: 2.1785 - val_sparse_categorical_accuracy: 0.2826\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1768 - sparse_categorical_accuracy: 0.2846 - val_loss: 2.1780 - val_sparse_categorical_accuracy: 0.2831\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1773 - sparse_categorical_accuracy: 0.2837 - val_loss: 2.1784 - val_sparse_categorical_accuracy: 0.2826\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1764 - sparse_categorical_accuracy: 0.2846 - val_loss: 2.1804 - val_sparse_categorical_accuracy: 0.2806\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1796 - sparse_categorical_accuracy: 0.2815 - val_loss: 2.1819 - val_sparse_categorical_accuracy: 0.2792\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1753 - sparse_categorical_accuracy: 0.2859 - val_loss: 2.1744 - val_sparse_categorical_accuracy: 0.2867\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1742 - sparse_categorical_accuracy: 0.2870 - val_loss: 2.1757 - val_sparse_categorical_accuracy: 0.2851\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1743 - sparse_categorical_accuracy: 0.2868 - val_loss: 2.1774 - val_sparse_categorical_accuracy: 0.2837\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1814 - sparse_categorical_accuracy: 0.2797 - val_loss: 2.1787 - val_sparse_categorical_accuracy: 0.2824\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1798 - sparse_categorical_accuracy: 0.2813 - val_loss: 2.1750 - val_sparse_categorical_accuracy: 0.2861\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 2.1749 - sparse_categorical_accuracy: 0.2861 - val_loss: 2.1758 - val_sparse_categorical_accuracy: 0.2853\n",
            "\n",
            "history dict: {'loss': [2.285062313079834, 2.269381046295166, 2.268730878829956, 2.223281145095825, 2.1880276203155518, 2.181415319442749, 2.1847448348999023, 2.184297800064087, 2.1817681789398193, 2.1805460453033447, 2.1862688064575195, 2.173813581466675, 2.176792860031128, 2.1874454021453857, 2.176612615585327, 2.1757709980010986, 2.1813786029815674, 2.17912220954895, 2.176250696182251, 2.1800894737243652, 2.1897130012512207, 2.1826047897338867, 2.1796936988830566, 2.17995548248291, 2.178412675857544, 2.18245005607605, 2.1784422397613525, 2.181851387023926, 2.1832306385040283, 2.18538761138916, 2.1825661659240723, 2.187466621398926, 2.1818394660949707, 2.1730170249938965, 2.173933982849121, 2.1756601333618164, 2.1831555366516113, 2.1791505813598633, 2.173712968826294, 2.174868106842041, 2.1767618656158447, 2.177255392074585, 2.1763906478881836, 2.1795849800109863, 2.1752777099609375, 2.174154281616211, 2.1743249893188477, 2.181406021118164, 2.1798155307769775, 2.174936294555664], 'sparse_categorical_accuracy': [0.17258000373840332, 0.19021999835968018, 0.19152000546455383, 0.2365799993276596, 0.2718999981880188, 0.2787199914455414, 0.27542001008987427, 0.27636000514030457, 0.27893999218940735, 0.28001999855041504, 0.27428001165390015, 0.2869200110435486, 0.28398001194000244, 0.27344000339508057, 0.28393998742103577, 0.2850399911403656, 0.2792400121688843, 0.2814599871635437, 0.2844800055027008, 0.2806999981403351, 0.2711000144481659, 0.27827998995780945, 0.2808600068092346, 0.2808400094509125, 0.2825799882411957, 0.27838000655174255, 0.2824999988079071, 0.27908000349998474, 0.27785998582839966, 0.2756800055503845, 0.2785399854183197, 0.2734600007534027, 0.2790600061416626, 0.2879999876022339, 0.28718000650405884, 0.2852799892425537, 0.2777000069618225, 0.2817400097846985, 0.2872599959373474, 0.28606000542640686, 0.2845799922943115, 0.28374001383781433, 0.2846199870109558, 0.28148001432418823, 0.28591999411582947, 0.286980003118515, 0.2867799997329712, 0.2797200083732605, 0.2812800109386444, 0.2861199975013733], 'val_loss': [2.276772975921631, 2.2721431255340576, 2.2691733837127686, 2.2311367988586426, 2.1772592067718506, 2.1765124797821045, 2.1945602893829346, 2.17655086517334, 2.1766250133514404, 2.221595287322998, 2.1748876571655273, 2.1745009422302246, 2.176131248474121, 2.183359146118164, 2.1761176586151123, 2.1793320178985596, 2.181387424468994, 2.1777706146240234, 2.1760036945343018, 2.1853861808776855, 2.217311143875122, 2.183255434036255, 2.175633668899536, 2.175936222076416, 2.185094118118286, 2.17460298538208, 2.1801981925964355, 2.1779465675354004, 2.1903042793273926, 2.186927318572998, 2.1818413734436035, 2.1798412799835205, 2.1748085021972656, 2.176292896270752, 2.1754462718963623, 2.176239490509033, 2.1792614459991455, 2.1765429973602295, 2.174345016479492, 2.1784873008728027, 2.1779773235321045, 2.1784422397613525, 2.1804277896881104, 2.1818854808807373, 2.1744351387023926, 2.17573881149292, 2.1774392127990723, 2.1787445545196533, 2.1750082969665527, 2.1758296489715576], 'val_sparse_categorical_accuracy': [0.18379999697208405, 0.18860000371932983, 0.1873999983072281, 0.2321999967098236, 0.28380000591278076, 0.28360000252723694, 0.2651999890804291, 0.2840000092983246, 0.28380000591278076, 0.2393999993801117, 0.28600001335144043, 0.2863999903202057, 0.2849000096321106, 0.2775999903678894, 0.2847999930381775, 0.2806999981403351, 0.27959999442100525, 0.2833999991416931, 0.2842000126838684, 0.27559998631477356, 0.2451000064611435, 0.27799999713897705, 0.28540000319480896, 0.28519999980926514, 0.2759999930858612, 0.2865000069141388, 0.2809000015258789, 0.2831999957561493, 0.27079999446868896, 0.2741999924182892, 0.2793000042438507, 0.28130000829696655, 0.28610000014305115, 0.2847999930381775, 0.2856000065803528, 0.2849000096321106, 0.28110000491142273, 0.28459998965263367, 0.28679999709129333, 0.2825999855995178, 0.2831000089645386, 0.2825999855995178, 0.28060001134872437, 0.2791999876499176, 0.2867000102996826, 0.2851000130176544, 0.28369998931884766, 0.2824000120162964, 0.28610000014305115, 0.28529998660087585]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maXkXyqnfRR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Importation Pour AutoEncoder \n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM_F3hqQmtaS",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Initialisation des données\n",
        "# Charger le jeu de données MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# reshape en (28, 28, 1)\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
        "# normaliser\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "input_shape = (image_size, image_size, 1)\n",
        "batch_size = 100\n",
        "kernel_size = 3\n",
        "latent_dim = 16\n",
        "layer_filters = [32, 64]\n",
        "inputs = Input(shape=input_shape, name='Encoder_input')\n",
        "latent_inputs = Input(shape=(latent_dim,), name='Decoder_input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWBrsyEAgh0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Encoder\n",
        "def Encoder(inputs,input_shape,kernel_size,latent_dim,layer_filters):\n",
        "  inputs = Input(shape=input_shape, name='Encoder_input')\n",
        "  x = inputs\n",
        "  # Conv2D(32)-Conv2D(64)\n",
        "  for filters in layer_filters:\n",
        "      x = Conv2D(filters=filters,\n",
        "                kernel_size=kernel_size,\n",
        "                activation='relu',\n",
        "                strides=2,\n",
        "                padding='same')(x)\n",
        "  shape = K.int_shape(x)\n",
        "\n",
        "  # générer un vecteur latent\n",
        "  x = Flatten()(x)\n",
        "  latent = Dense(latent_dim, name='latent_vector')(x)\n",
        "\n",
        "  encoder = Model(inputs, latent, name='Encoder')\n",
        "  encoder.summary()\n",
        "  plot_model(encoder, to_file='Encoder.png', show_shapes=True)\n",
        "  return encoder,shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiMS9ccFhv8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Decoder\n",
        "def Decoder(latent_inputs,kernel_size,layer_filters,shape):\n",
        "  x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
        "  x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "  # Conv2DTranspose(64)-Conv2DTranspose(32)\n",
        "  for filters in layer_filters[::-1]:\n",
        "      x = Conv2DTranspose(filters=filters,\n",
        "                          kernel_size=kernel_size,\n",
        "                          activation='relu',\n",
        "                          strides=2,\n",
        "                          padding='same')(x)\n",
        "\n",
        "  outputs = Conv2DTranspose(filters=1,\n",
        "                            kernel_size=kernel_size,\n",
        "                            activation='sigmoid',\n",
        "                            padding='same',\n",
        "                            name='Decoder_output')(x)\n",
        "\n",
        "  # instantiate decoder model\n",
        "  decoder = Model(latent_inputs, outputs, name='Decoder')\n",
        "  decoder.summary()\n",
        "  plot_model(decoder, to_file='Decoder.png', show_shapes=True)\n",
        "  return decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMv1SI-jiriq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Auto-Encoder = Encoder + Decoder\n",
        "def AutoEncoder(inputs,batch_size,encoder,decoder,x_train,x_test):\n",
        "  autoencoder = Model(inputs, decoder(encoder(inputs)), name='Autoencoder')\n",
        "  autoencoder.summary()\n",
        "  plot_model(autoencoder, to_file='Auto_Encoder.png', show_shapes=True)\n",
        "  autoencoder.compile(loss='mse', optimizer='adam')\n",
        "  autoencoder.fit(x_train,\n",
        "                  x_train,\n",
        "                  validation_data=(x_test, x_test),\n",
        "                  epochs=1,\n",
        "                  batch_size=batch_size)\n",
        "  x_decoded = autoencoder.predict(x_test)\n",
        "  return autoencoder,x_decoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arx0P9ADHDP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "outputId": "ed217657-4b89-4830-c7a3-ad20c899ed0f"
      },
      "source": [
        "#@title Run\n",
        "encoder,shape = Encoder(inputs,input_shape,kernel_size,latent_dim,layer_filters)\n",
        "decoder = Decoder(latent_inputs,kernel_size,layer_filters,shape)\n",
        "autoencoder,x_decoded = AutoEncoder(inputs,batch_size,encoder,decoder,x_train,x_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 14, 14, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "latent_vector (Dense)        (None, 16)                50192     \n",
            "=================================================================\n",
            "Total params: 69,008\n",
            "Trainable params: 69,008\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"Decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Decoder_input (InputLayer)   [(None, 16)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3136)              53312     \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 32)        18464     \n",
            "_________________________________________________________________\n",
            "Decoder_output (Conv2DTransp (None, 28, 28, 1)         289       \n",
            "=================================================================\n",
            "Total params: 108,993\n",
            "Trainable params: 108,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"Autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "Encoder (Model)              (None, 16)                69008     \n",
            "_________________________________________________________________\n",
            "Decoder (Model)              (None, 28, 28, 1)         108993    \n",
            "=================================================================\n",
            "Total params: 178,001\n",
            "Trainable params: 178,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "600/600 [==============================] - 89s 149ms/step - loss: 0.0372 - val_loss: 0.0134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9_NNctYih6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "1e2cf8fb-f352-4928-85e5-d4240f3e1c64"
      },
      "source": [
        "#@title Image final\n",
        "imgs = np.concatenate([x_test[:8], x_decoded[:8]])\n",
        "imgs = imgs.reshape((4, 4, image_size, image_size))\n",
        "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
        "plt.figure()\n",
        "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
        "plt.savefig('input_and_decoded.png')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}